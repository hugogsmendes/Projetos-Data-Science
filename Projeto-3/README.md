# üöó Previs√£o de Pre√ßos de Ve√≠culos com Regress√£o Linear

## Contexto do Projeto

Este projeto representa uma imers√£o profunda na aplica√ß√£o e diagn√≥stico de modelos de **Regress√£o Linear** para um problema cl√°ssico de previs√£o de pre√ßos de ve√≠culos. O objetivo principal n√£o foi apenas construir um modelo, mas sim executar um ciclo completo e iterativo de Data Science, compreendendo os desafios reais do pr√©-processamento, da sele√ß√£o de features e da avalia√ß√£o cr√≠tica dos resultados.

A an√°lise documenta uma jornada de **14 itera√ß√µes de modelagem**, explorando os limites do modelo linear e destacando a import√¢ncia de cada etapa do processo para a constru√ß√£o de um modelo robusto e confi√°vel.

##  Metodologia e Jornada Anal√≠tica

Este projeto foi muito mais do que um simples treinamento de modelo. Foi um exerc√≠cio completo que passou pelas seguintes etapas:

## a. Limpeza e Pr√©-processamento de Dados
- **Tratamento de Dados Ausentes:** An√°lise e remo√ß√£o de valores nulos (`NaN`) para garantir a integridade do dataset.
- **Detec√ß√£o de "Dados Sujos":** Utiliza√ß√£o de t√©cnicas de an√°lise de padr√µes e frequ√™ncia (`.value_counts()`, `.str.len()`) para identificar e limpar registros que, embora n√£o nulos, n√£o continham informa√ß√£o relevante.
- **An√°lise e Tratamento de Outliers:** Identifica√ß√£o de valores extremos nas vari√°veis `mileage` e `price` atrav√©s de box plots. A decis√£o estrat√©gica de manter os outliers inicialmente e remov√™-los em itera√ß√µes posteriores foi crucial para entender seu impacto no modelo.

## b. Engenharia e Transforma√ß√£o de Features
- **Encoding de Vari√°veis Categ√≥ricas:**
    - **Experimenta√ß√£o com `LabelEncoder`:** Uma an√°lise inicial foi feita, mas concluiu-se que este m√©todo criava uma ordem num√©rica falsa e prejudicial ao modelo.
    - **Implementa√ß√£o de `One-Hot Encoding`:** A t√©cnica correta (`pd.get_dummies`) foi aplicada, incluindo estrat√©gias para lidar com **alta cardinalidade** (agrupamento de categorias raras), o que resultou em uma melhora dr√°stica no desempenho do modelo.
- **Cria√ß√£o de Intervalos (Binning):** Uso da fun√ß√£o `pd.cut()` para transformar vari√°veis num√©ricas cont√≠nuas (como quilometragem) em faixas categ√≥ricas, facilitando an√°lises e visualiza√ß√µes.

## c. An√°lise Explorat√≥ria de Dados (EDA)
- An√°lise aprofundada das medidas de tend√™ncia central e dispers√£o, com foco na compara√ß√£o entre **m√©dia e mediana** para entender a assimetria das distribui√ß√µes.
- Verifica√ß√£o da distribui√ß√£o de cada vari√°vel com **histogramas** e testes de normalidade (**Shapiro-Wilk**), concluindo que as vari√°veis n√£o seguiam uma distribui√ß√£o normal.
- An√°lise de correla√ß√£o utilizando o **Teste de Spearman** (adequado para dados n√£o-normais) e visualiza√ß√£o com **heatmaps** para identificar as features mais promissoras.

## d. Modelagem Iterativa e Avalia√ß√£o
- **Constru√ß√£o de 14 Modelos:** O cora√ß√£o do projeto foi o processo iterativo de treinar, avaliar e refinar.
- **Sele√ß√£o de Features:** Utiliza√ß√£o do **p-valor** dos coeficientes do modelo (extra√≠do dos resultados da regress√£o OLS) para remover vari√°veis n√£o significativas.
- **Diagn√≥stico de Multicolinearidade:** An√°lise da correla√ß√£o entre features e investiga√ß√£o de avisos de `Condition Number` alto, com c√°lculo do **VIF (Variance Inflation Factor)** para confirmar a redund√¢ncia entre vari√°veis.
- **Avalia√ß√£o de M√©tricas:** An√°lise criteriosa do **R¬≤** e do **R¬≤ Ajustado**. A compara√ß√£o entre o score de treino e o de teste foi fundamental para identificar um caso real de **overfitting** em um dos modelos.
- **An√°lise de Res√≠duos:** Verifica√ß√£o dos res√≠duos do modelo final, incluindo a an√°lise de sua soma (`SQE`) e o teste de normalidade, que confirmou a natureza n√£o-linear do problema.

## Principais Descobertas e Conclus√µes

1.  **Impacto do Encoding:** A troca do `LabelEncoder` pelo `One-Hot Encoding` foi a otimiza√ß√£o mais impactante, fazendo o **R¬≤ do modelo saltar de ~40% para ~65%**. Isso provou na pr√°tica a import√¢ncia de representar corretamente os dados categ√≥ricos.
2.  **Limites da Regress√£o Linear:** Mesmo ap√≥s todas as otimiza√ß√µes, o modelo final estabilizou com um **R¬≤ de 63%**. A an√°lise dos res√≠duos (que n√£o se mostraram normais) confirmou a tese de que a rela√ß√£o entre as caracter√≠sticas dos carros e seus pre√ßos √© intrinsecamente **n√£o-linear**, e um modelo linear, por melhor que seja ajustado, tem um teto de performance.
3.  **Overfitting na Pr√°tica:** A compara√ß√£o entre um modelo com R¬≤ de treino de 0.70 (com vari√°veis n√£o significativas) e o modelo final com R¬≤ de treino de 0.63 (apenas com vari√°veis significativas) demonstrou um caso claro de overfitting. O modelo mais simples (0.63) **generalizou melhor e teve um desempenho superior nos dados de teste**.
4.  **A Import√¢ncia do Processo:** A maior conclus√£o do projeto √© o valor do processo iterativo. Cada uma das 14 itera√ß√µes revelou uma nova caracter√≠stica dos dados ou uma limita√ß√£o do modelo, guiando para o pr√≥ximo passo l√≥gico e construindo um entendimento profundo do problema.

## Habilidades Demonstradas

- **Pr√©-processamento de Dados Completo:** Limpeza, transforma√ß√£o, tratamento de outliers e encoding.
- **An√°lise Explorat√≥ria e Estat√≠stica:** Testes de hip√≥tese (Teste T, Shapiro-Wilk), an√°lise de correla√ß√£o (Spearman, p-valor).
- **Modelagem Preditiva com Regress√£o Linear:** Treinamento, avalia√ß√£o de m√©tricas (R¬≤, R¬≤ Ajustado, SQE).
- **Diagn√≥stico Avan√ßado de Modelos:** An√°lise de res√≠duos, diagn√≥stico de multicolinearidade (VIF), identifica√ß√£o de overfitting.
- **Resolu√ß√£o de Problemas e Racioc√≠nio Cr√≠tico:** Itera√ß√£o e formula√ß√£o de hip√≥teses para explicar o comportamento do modelo.